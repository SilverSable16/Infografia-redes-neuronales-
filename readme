
# Desvelando las Redes Neuronales: Una Guía Visual de los Cerebros de la IA Moderna


## Sección 1: La Idea Central: ¿Qué es una Red Neuronal?

En el núcleo de la revolución de la inteligencia artificial se encuentra un paradigma computacional profundamente inspirado en la biología: la red neuronal. Este enfoque para el procesamiento de la información no solo ha redefinido las capacidades de las máquinas, sino que también ha establecido un nuevo horizonte para la resolución de problemas complejos que durante mucho tiempo se consideraron exclusivos del dominio humano.

### 1.1 La Definición: Aprendiendo de los Datos, Inspirado en el Cerebro

Una red neuronal artificial (RNA) es un sistema de computación cuyo diseño emula la estructura y el funcionamiento de las redes neuronales del cerebro humano. En su esencia, es un modelo matemático compuesto por unidades de procesamiento interconectadas, denominadas neuronas artificiales o nodos, que colaboran para procesar información y resolver problemas. A diferencia de la computación tradicional, que opera siguiendo un conjunto de instrucciones explícitas, las redes neuronales están diseñadas para aprender directamente de los datos.

La función principal de estas redes es identificar patrones complejos, relaciones subyacentes y estructuras ocultas dentro de grandes volúmenes de datos. Esta capacidad les permite realizar tareas que son extraordinariamente difíciles para los algoritmos convencionales, como reconocer un rostro familiar en una multitud, comprender el lenguaje natural o diagnosticar enfermedades a partir de imágenes médicas. Al aprender de ejemplos, las redes neuronales pueden tomar decisiones inteligentes con una intervención humana limitada, creando sistemas adaptables que mejoran continuamente su rendimiento a medida que se exponen a más información. Este modelo de aprendizaje, inspirado en cómo las neuronas biológicas se activan e intercambian señales, ha demostrado ser excepcionalmente poderoso para abordar problemas no lineales y complejos del mundo real.

### 1.2 Ventajas Clave: Los Superpoderes de las Redes Neuronales

La adopción generalizada de las redes neuronales se debe a un conjunto único de ventajas que las distinguen de otros métodos computacionales. Estas capacidades inherentes les permiten abordar una amplia gama de desafíos con una eficacia y flexibilidad sin precedentes.

- Aprendizaje Adaptativo: La ventaja más fundamental de una red neuronal es su capacidad para aprender a realizar tareas basándose en la experiencia o el entrenamiento, en lugar de ser programada explícitamente. A través de un proceso de ajuste iterativo de sus parámetros internos (conocidos como pesos), la red se adapta a los datos de entrada, mejorando su precisión y rendimiento con el tiempo.

- Tolerancia a Fallos y Robustez: La información en una red neuronal no se almacena en una única ubicación, sino que está distribuida a través de toda la red de conexiones. Esta naturaleza distribuida confiere una notable tolerancia a fallos. Si una parte de la red se daña o se elimina, el sistema a menudo puede seguir funcionando, aunque con una degradación gradual de su rendimiento. Del mismo modo, son robustas frente a datos de entrada ruidosos, incompletos o distorsionados, ya que pueden aprender a reconocer los patrones subyacentes a pesar de las imperfecciones.

- Procesamiento Paralelo y Operación en Tiempo Real: La estructura de una red neuronal es inherentemente paralela. Los cálculos dentro de cada capa pueden realizarse de forma simultánea, lo que las hace ideales para ser implementadas en hardware especializado como las Unidades de Procesamiento Gráfico (GPU). Esta capacidad de procesamiento masivo en paralelo permite que las redes neuronales operen en tiempo real, una característica crucial para aplicaciones como los vehículos autónomos o el análisis de vídeo en directo.

- Auto-organización: Durante la fase de aprendizaje, una red neuronal puede crear su propia representación y organización interna de la información que recibe. Es capaz de descubrir características y patrones latentes en los datos sin guía explícita, organizando la información de una manera que sea óptima para la tarea en cuestión.

### 1.3 Una Línea de Tiempo Visual: Hitos Históricos Clave

El camino de las redes neuronales desde un concepto teórico hasta la tecnología transformadora que es hoy ha estado marcado por períodos de gran optimismo, seguidos de estancamiento y un resurgimiento espectacular.

- 1943 — La Chispa: Los neurofisiólogo Warren McCulloch y el lógico Walter Pitts sentaron las bases teóricas al proponer el primer modelo matemático de una neurona artificial. Su trabajo demostró que una red de estas neuronas simplificadas podía, en teoría, calcular cualquier función lógica o aritmética.

- 1957 — El Perceptrón: El psicólogo Frank Rosenblatt desarrolló el Perceptrón, la primera red neuronal práctica capaz de aprender a través de un algoritmo de entrenamiento. El Perceptrón fue diseñado para el reconocimiento de patrones y su creación generó un inmenso entusiasmo. La cobertura mediática de la época fue extraordinariamente optimista; un artículo del New York Times de 1958 describía el Perceptrón como "el embrión de un ordenador electrónico que [la Armada] espera que sea capaz de caminar, hablar, ver, escribir, reproducirse y ser consciente de su existencia". Este nivel de expectación sentó las bases para una futura desilusión.

- 1969 — El "Invierno de la IA": El libro *Perceptrons* de Marvin Minsky y Seymour Papert supuso un punto de inflexión crítico. En él, demostraron matemáticamente las limitaciones fundamentales del Perceptrón de una sola capa. La limitación más famosa era su incapacidad para resolver problemas que no son linealmente separables, como la simple función lógica XOR. Una red de una sola capa solo puede trazar una única línea para separar clases de datos. Esta revelación pública de una limitación tan fundamental, después de años de grandes promesas, provocó una crisis de confianza en todo el enfoque conexionista. Como resultado, la financiación para la investigación en redes neuronales se desplomó drásticamente, dando inicio a un período conocido como el "invierno de la IA".

- 1986 — El Renacimiento: El campo experimentó un resurgimiento espectacular con la popularización del algoritmo de retropropagación (*backpropagation*) por parte de David Rumelhart, Geoffrey Hinton y Ronald J. Williams. Aunque el concepto había sido desarrollado previamente por otros, fue su trabajo el que demostró su eficacia para entrenar redes neuronales de múltiples capas (o profundas). Este algoritmo proporcionó un método eficiente para superar la limitación del Perceptrón, ya que permitía a las redes con capas ocultas aprender representaciones complejas y no lineales. La retropropagación fue la clave que desbloqueó el potencial de las redes profundas, poniendo fin al "invierno de la IA" y sentando las bases para la revolución del aprendizaje profundo décadas más tarde.

---

## Sección 2: El Bloque de Construcción: Anatomía de una Neurona Artificial

Para comprender el funcionamiento de una red neuronal en su conjunto, es esencial primero deconstruir su componente más fundamental: la neurona artificial. También conocida como nodo o perceptrón, esta unidad de cálculo es una abstracción matemática de su contraparte biológica, diseñada para recibir, procesar y transmitir señales dentro de la red.

### 2.1 Diagrama Anotado de una Neurona

Una neurona artificial es, en esencia, una máquina de dos partes: una primera parte que realiza una operación lineal y una segunda que introduce una no linealidad. La combinación de muchas de estas unidades simples en capas es lo que dota a la red de su poder computacional. Un diagrama detallado revela sus componentes clave:

- Entradas (x1, x2, ...): Son los datos numéricos que la neurona recibe. Pueden ser las características de una muestra de datos (por ejemplo, los valores de los píxeles de una imagen) o las salidas de otras neuronas de una capa anterior.

- Pesos (w1, w2, ...): Cada conexión de entrada tiene un peso asociado. Este valor numérico determina la importancia o la influencia de esa entrada específica en la salida de la neurona. Un peso alto significa que la entrada tiene un gran efecto, mientras que un peso cercano a cero significa que tiene poco efecto. Estos pesos son los parámetros fundamentales que la red aprende y ajusta durante el proceso de entrenamiento. Controlan la "pendiente" o la fuerza de la conexión.

- Sesgo (b): Es un valor numérico constante que se suma a la entrada total ponderada. El sesgo no depende de ninguna entrada y actúa como un término de ajuste, similar a la ordenada en el origen en una ecuación lineal (y = mx + b). Permite desplazar la función de activación hacia la izquierda o la derecha, lo que es crucial para que el modelo se ajuste correctamente a los datos. En la práctica, el sesgo determina el "punto de activación" de la neurona; un sesgo muy negativo requerirá una entrada ponderada muy alta para que la neurona se active.

- Función de Suma (Σ): La neurona calcula la suma ponderada de todas sus entradas. Cada entrada xi se multiplica por su peso correspondiente wi, y todos estos productos se suman, junto con el sesgo b. Este paso agrega toda la información entrante en un único valor.

- Función de Activación (f): Este es el componente no lineal. La función de activación toma la suma ponderada total como entrada y la transforma para producir la salida final de la neurona. Esta función decide si la neurona debe "disparar" (activarse) y con qué intensidad. La introducción de la no linealidad es lo que permite a la red aprender patrones complejos que van más allá de las relaciones lineales simples.

### 2.2 El Cálculo: De las Entradas a la Salida

El flujo de información a través de una única neurona sigue una secuencia de pasos matemáticos bien definidos. Este proceso transforma múltiples entradas en una única salida.

1. Recepción de Entradas: La neurona recibe un vector de entradas, por ejemplo, x1, x2, x3.
2. Ponderación de Entradas: Cada entrada es multiplicada por su peso correspondiente: (x1·w1), (x2·w2), (x3·w3).
3. Suma Ponderada y Sesgo: Los productos ponderados se suman y se les añade el sesgo para obtener un valor agregado: Suma = (x1·w1) + (x2·w2) + (x3·w3) + b.
4. Aplicación de la Función de Activación: El valor de la suma se pasa a través de la función de activación para generar la salida final de la neurona: Salida = f(Suma).

Este proceso completo puede resumirse en una única fórmula matemática compacta, que encapsula la operación fundamental de una neurona artificial:

Salida = f(Σ(wi·xi) + b)

Si una red neuronal estuviera compuesta únicamente por la parte lineal (la suma ponderada), sin importar cuántas capas tuviera, seguiría siendo un modelo lineal, incapaz de capturar la complejidad del mundo real. La función de activación es el ingrediente crucial que rompe esta linealidad. Al encadenar estas unidades en capas, donde la salida no lineal de una capa se convierte en la entrada de la siguiente, la red puede aproximar funciones arbitrariamente complejas, lo que constituye la esencia del aprendizaje profundo.

---

## Sección 3: El Motor de Aprendizaje: Cómo se Entrena una Red

El verdadero poder de una red neuronal no reside en su estructura estática, sino en su capacidad para aprender de los datos a través de un proceso dinámico y iterativo conocido como entrenamiento. Este proceso puede conceptualizarse como un ciclo de cuatro pasos interdependientes, donde la red realiza una predicción, evalúa su error, determina la causa de dicho error y, finalmente, se corrige a sí misma para mejorar en el siguiente intento.

### 3.1 El Bucle de Entrenamiento: Un Ciclo de Cuatro Pasos

El entrenamiento de una red neuronal es un problema de optimización. El objetivo es encontrar el conjunto de pesos y sesgos que minimice el error de la red en un conjunto de datos de entrenamiento. Este objetivo se logra repitiendo un ciclo de cuatro etapas miles o millones de veces.

- Paso 1: Propagación hacia Adelante (La Predicción)

	El proceso comienza con la alimentación de una muestra de datos de entrada (por ejemplo, una imagen) en la primera capa de la red. Cada capa de neuronas procesa las salidas de la capa anterior, realizando su cálculo de suma ponderada y aplicando su función de activación. La información fluye hacia adelante, capa por capa, como una señal que atraviesa el sistema, hasta que la capa de salida final produce una predicción. En las primeras iteraciones, con pesos y sesgos inicializados aleatoriamente, esta predicción será esencialmente una conjetura aleatoria.

- Paso 2: Cálculo de la Pérdida (La Verificación de la Realidad)

	Una vez que la red ha generado una predicción, esta se compara con el valor real o la etiqueta correcta correspondiente a los datos de entrada. Esta comparación se realiza mediante una función de pérdida (también llamada función de coste). La función de pérdida cuantifica la discrepancia entre la predicción del modelo y la verdad, produciendo un único valor numérico que representa el "error". Un valor de pérdida alto indica una predicción muy imprecisa, mientras que un valor cercano a cero indica una predicción casi perfecta. El objetivo de todo el proceso de entrenamiento es minimizar este valor de pérdida.

- Paso 3: Retropropagación (La Asignación de la Culpa)

	Este es el mecanismo central del aprendizaje. La retropropagación (del inglés backpropagation) es un algoritmo que determina cómo contribuyó cada peso y sesgo individual en la red al error total calculado por la función de pérdida. Para ello, utiliza la regla de la cadena del cálculo diferencial para calcular eficientemente el gradiente de la función de pérdida con respecto a cada parámetro de la red. El gradiente es un vector que apunta en la dirección del aumento más pronunciado del error. En esencia, la retropropagación responde a la pregunta: "¿En qué dirección y con qué magnitud debo cambiar este peso específico para reducir el error final?". El algoritmo funciona propagando la señal de error hacia atrás, desde la capa de salida hasta la capa de entrada, asignando la "culpa" a cada conexión a lo largo del camino.

- Paso 4: Optimización (La Corrección)

	Con los gradientes calculados por la retropropagación, un algoritmo de optimización actualiza los pesos y sesgos de la red. El método más fundamental es el Descenso del Gradiente. Este algoritmo ajusta cada parámetro dando un pequeño paso en la dirección opuesta al gradiente. Moverse en la dirección opuesta al gradiente es análogo a dar un paso cuesta abajo en la "superficie de pérdida", un paisaje multidimensional donde la altitud representa el error. Al repetir este proceso, la red desciende gradualmente por esta superficie, buscando el punto más bajo posible, que corresponde al conjunto de pesos que minimiza el error.

Estos cuatro pasos forman un sistema inseparable. La propagación hacia adelante genera la predicción que la función de pérdida evalúa. La función de pérdida crea la señal de error que la retropropagación descompone. La retropropagación calcula los gradientes que el algoritmo de optimización utiliza para actualizar la red. Este ciclo, repetido sobre muchas muestras de datos, es lo que permite a la red "aprender". El paisaje de pérdida de una red neuronal real es increíblemente complejo, con miles de millones de dimensiones y múltiples valles (mínimos locales). El descenso del gradiente es un algoritmo de búsqueda local que no ve todo el paisaje, solo la pendiente inmediata. Esta limitación es una de las principales razones por las que se han desarrollado algoritmos de optimización más avanzados.

---

## Sección 4: El Panel de Control: Mecanismos y Decisiones Clave

El diseño y entrenamiento de una red neuronal eficaz implica una serie de decisiones críticas que actúan como un panel de control para el científico de datos. Estos mecanismos —funciones de activación, algoritmos de optimización y técnicas de regularización— son fundamentales para gobernar el comportamiento de la red, mejorar su rendimiento y, lo que es más importante, asegurar que pueda generalizar su aprendizaje a datos nuevos y no vistos. Son las herramientas que hacen que el aprendizaje profundo sea una disciplina práctica y no solo una curiosidad teórica.

### 4.1 Funciones de Activación: Introduciendo la No Linealidad

Las funciones de activación son el componente que permite a las redes neuronales aprender relaciones complejas y no lineales. Sin ellas, una red de múltiples capas, por profunda que fuera, se comportaría como un simple modelo lineal, incapaz de capturar la riqueza de los datos del mundo real. Su propósito es tomar la salida sumada de una neurona y transformarla en una señal de activación que se pasa a la siguiente capa, decidiendo si la neurona debe "activarse" y en qué medida. La elección de la función de activación es una decisión de diseño crucial que ha evolucionado con el tiempo para resolver problemas específicos del entrenamiento.

La siguiente tabla compara las funciones de activación más comunes, destacando su evolución y sus casos de uso específicos. Esta comparación encapsula una narrativa clave en la investigación de redes neuronales: el paso de funciones que sufrían de problemas como el desvanecimiento del gradiente a funciones más robustas y computacionalmente eficientes que han permitido el entrenamiento de redes mucho más profundas.

| Función | Rango de salida | Características clave y casos de uso |
|---|---|---|
| Sigmoide | (0, 1) | Pros: La salida puede interpretarse como una probabilidad. Contras: Sufre del problema del gradiente desvaneciente; no centrada en cero. Mejor para: capa de salida en clasificación binaria. |
| Tanh | (-1, 1) | Pros: centrada en cero, puede acelerar convergencia respecto a sigmoide. Contras: aún sufre gradiente desvaneciente en extremos. |
| ReLU | (-∞, ∞) para salida positiva | Popular por su simplicidad y eficacia; problema: neuronas "muertas". |
| Leaky ReLU | (-∞, ∞) | Variante de ReLU con pequeña pendiente para valores negativos. |
| Softmax | (0, 1) (vector) | Convierte logits en probabilidades; ideal para salida multiclase. |

### 4.2 Algoritmos de Optimización: Encontrando el Mínimo Más Rápido

Si el Descenso del Gradiente es el concepto fundamental para la optimización, los algoritmos más avanzados son las herramientas que hacen que el entrenamiento de redes profundas sea factible en la práctica. Estos optimizadores están diseñados para navegar por los complejos paisajes de pérdida de manera más eficiente, acelerando la convergencia y ayudando a evitar mínimos locales deficientes. La elección de la tasa de aprendizaje es crítica: si es demasiado pequeña, la convergencia es lenta; si es demasiado grande, el entrenamiento puede volverse inestable y divergir. Los optimizadores adaptativos abordan este problema.

- Momentum: Ayuda a acelerar el descenso del gradiente en la dirección correcta y amortigua las oscilaciones; añade una fracción del vector de actualización anterior.
- RMSprop: Adapta la tasa de aprendizaje para cada parámetro en función de una media móvil de gradientes al cuadrado.
- Adam: Combina Momentum y RMSprop, mantiene medias móviles del primer y segundo momento —opción por defecto en muchos problemas.

### 4.3 Regularización: Previniendo el Sobreajuste

El sobreajuste (overfitting) es uno de los mayores desafíos en el machine learning. Ocurre cuando un modelo aprende los datos de entrenamiento "demasiado bien", capturando no solo los patrones subyacentes sino también el ruido y las peculiaridades aleatorias del conjunto de datos. Como resultado, el modelo funciona perfectamente con los datos que ha visto, pero no logra generalizar a datos nuevos y no vistos. Las técnicas de regularización son un conjunto de estrategias diseñadas para combatir el sobreajuste al penalizar la complejidad del modelo.

- Regularización L1 y L2: Añaden un término de penalización a la función de pérdida basado en la magnitud de los pesos (L2 = weight decay; L1 favorece sparsity).
- Dropout: "Apaga" aleatoriamente neuronas durante el entrenamiento para forzar representaciones más robustas.
- Early Stopping: Detiene el entrenamiento cuando la performance en el conjunto de validación deja de mejorar.

---

## Sección 5: El Zoo de las Redes Neuronales: Una Guía de Campo de Arquitecturas

El término "red neuronal" abarca una vasta y diversa familia de arquitecturas, cada una diseñada y optimizada para un tipo específico de datos y tarea. La evolución desde el Perceptrón Multicapa (MLP) fundamental hacia arquitecturas más especializadas como las Redes Neuronales Convolucionales (CNN) y las Redes Neuronales Recurrentes (RNN) es una historia de especialización impulsada por la naturaleza de los datos. La arquitectura de una red no es arbitraria; impone un "sesgo inductivo", una suposición previa sobre la estructura del problema, que es clave para su éxito.

### 5.1 Perceptrón Multicapa (MLP): El Todoterreno

El Perceptrón Multicapa es la arquitectura de red neuronal canónica y fundamental. Consiste en una capa de entrada, una o más capas ocultas y una capa de salida. Su característica definitoria es que las neuronas de cada capa están completamente conectadas a todas las neuronas de la capa siguiente, lo que se conoce como capas "densas". Esta conectividad total hace que el MLP sea un aproximador de funciones universal, pero también computacionalmente costoso y propenso al sobreajuste si no se regulariza adecuadamente.

Ideal para: problemas de clasificación y regresión con datos estructurados o tabulares.

### 5.2 Redes Neuronales Convolucionales (CNN): El Especialista en Visión

Las Redes Neuronales Convolucionales representan un salto cualitativo en el procesamiento de datos con estructura de cuadrícula, como las imágenes. Su diseño está directamente inspirado en la organización de la corteza visual humana. En lugar de conectar cada neurona de entrada a cada neurona oculta (lo que sería inviable para imágenes de alta resolución), las CNN utilizan capas especializadas para explotar la jerarquía espacial de las imágenes.

Capas clave:

- Capa convolucional: aplica filtros aprendibles (kernels) para extraer mapas de características.
- Capa de pooling: reduce dimensiones espaciales y proporciona invarianza a traslaciones.

Ideal para: visión por computadora — clasificación, detección, segmentación, análisis médico.

### 5.3 Redes Neuronales Recurrentes (RNN): El Maestro de las Secuencias

Las RNN están diseñadas para manejar datos secuenciales donde el orden importa (lenguaje, series temporales). La característica definitoria es su bucle recurrente: la salida en un paso influye en el siguiente, permitiendo un tipo de "memoria".

Problema: RNN simples sufren gradiente desvaneciente o explosivo en secuencias largas.

Variantes avanzadas:

- LSTM (Long Short-Term Memory): unidades con una célula de memoria y compuertas (entrada, olvido, salida) que permiten conservar información a largo plazo.
- GRU (Gated Recurrent Unit): versión más simple de LSTM, con menos parámetros.

Ideal para: PLN, reconocimiento de voz, generación de texto, predicción de series temporales.

---

## Sección 6: Las Redes Neuronales en Nuestro Mundo: Aplicaciones en el Mundo Real

Después de explorar los fundamentos teóricos, los mecanismos de entrenamiento y las diversas arquitecturas, es crucial conectar estos conceptos con las aplicaciones tangibles que dan forma a nuestra vida diaria. Las redes neuronales no son una tecnología abstracta confinada a los laboratorios de investigación; son el motor invisible detrás de muchos de los servicios y productos más innovadores de la actualidad. Su capacidad para extraer patrones significativos de datos masivos y no estructurados ha desencadenado una ola de avances en prácticamente todas las industrias. La conexión entre las arquitecturas especializadas y estas aplicaciones es directa: la estructura de la red está intrínsecamente ligada al problema que resuelve.

### 6.1 Un Escaparate de Aplicaciones

**Procesamiento del Lenguaje Natural (PLN)**

Tecnología clave: RNN (LSTM/GRU) y Transformers.

Aplicaciones:

- Asistentes virtuales y chatbots (p. ej. modelos de lenguaje grandes).
- Traducción automática.
- Análisis de sentimientos.

**Visión por Computadora**

Tecnología clave: CNN.

Aplicaciones:

- Vehículos autónomos (detección de peatones, señales).
- Diagnóstico médico por imagen.
- Reconocimiento facial.

**Sistemas de Recomendación**

Tecnología clave: MLP y arquitecturas híbridas.

Aplicaciones:

- E‑commerce y entretenimiento: recomendaciones personalizadas.

**Salud y Medicina**

Tecnología clave: CNN para imágenes; MLP para datos tabulares.

Aplicaciones:

- Descubrimiento de fármacos.
- Medicina personalizada.

**Finanzas y Comercio**

Tecnología clave: MLP y RNN para series temporales.

Aplicaciones:

- Detección de fraude.
- Trading algorítmico.

**Industria y Robótica**

Tecnología clave: CNN para visión robótica; MLP para control.

Aplicaciones:

- Automatización industrial.
- Predicción de fallos y optimización de procesos.

El hilo conductor que une todas estas aplicaciones es la capacidad de las redes neuronales para aprender representaciones útiles directamente de datos sin procesar, reemplazando la necesidad de diseñar manualmente reglas o características específicas.

---

## Recursos, estructura recomendada y contribución

- Estructura sugerida del repositorio:
	- `data/` — datasets
	- `notebooks/` — experimentos y visualizaciones
	- `models/` — checkpoints y definiciones
	- `Infografia/` — imágenes y materiales visuales (ya presente)

- Cómo contribuir:
	1. Crea una rama o fork.
	2. Añade tu material en `notebooks/` o `examples/`.
	3. Abre un pull request con descripción clara.

---

## Licencia

Especifica aquí la licencia deseada (por ejemplo, MIT). Si prefieres, lo configuro por defecto como MIT y añado el archivo `LICENSE`.

---

**Fin del documento: contenido completo incluido (sin resumir).**

---

## Tabla de contenidos

- Introducción
- Anatomía de una neurona
- Cómo se entrena una red
- Mecanismos clave (activaciones, optimizadores, regularización)
- Arquitecturas principales (MLP, CNN, RNN)
- Aplicaciones reales
- Cómo contribuir
- Licencia

---

## ✨ Resumen

Una red neuronal artificial (RNA) es un modelo inspirado en el cerebro que aprende de datos ajustando parámetros (pesos y sesgos). Son especialmente poderosas para detectar patrones complejos en imágenes, texto y series temporales.

## 🧠 Anatomía de una neurona (breve)

- Entradas (x1, x2, ...)
- Pesos (w1, w2, ...)
- Sesgo (b)
- Suma ponderada: z = Σ(wi·xi) + b
- Activación: y = f(z)  (introduce la no linealidad)

> Nota: La combinación de capas con funciones de activación es lo que permite aproximar funciones complejas.

## ⚙️ Cómo se entrena una red (en 4 pasos)

1. Propagación hacia adelante — la red produce una predicción.
2. Cálculo de la pérdida — se compara la predicción con la verdad.
3. Retropropagación — se calculan gradientes para asignar "culpa" a parámetros.
4. Optimización — se actualizan pesos y sesgos (ej. SGD, Adam).

## 🔧 Mecanismos y decisiones clave

- Funciones de activación: Sigmoide, Tanh, ReLU, Leaky ReLU, Softmax.
- Optimizadores: SGD, Momentum, RMSprop, Adam (recomendado por defecto).
- Regularización: L1/L2, Dropout, Early Stopping.

## 🧭 Arquitecturas destacadas

- MLP: redes densas para datos tabulares.
- CNN: visión por computadora (clasificación, detección, segmentación).
- RNN / LSTM / GRU: secuencias y lenguaje (traducción, reconocimiento de voz).

## 🌍 Aplicaciones reales (selección)

- PLN: asistentes virtuales, traducción automática, análisis de sentimientos.
- Visión: vehículos autónomos, diagnóstico médico por imagen, reconocimiento facial.
- Recomendaciones: personalización en e‑commerce y streaming.
- Salud: descubrimiento de fármacos, medicina personalizada.
